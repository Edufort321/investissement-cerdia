import { NextResponse } from 'next/server'
import type { NextRequest } from 'next/server'
import { createClient } from '@supabase/supabase-js'

// ‚úÖ D√©sactivation temporaire des erreurs bloquantes pour permettre le build
const SUPABASE_URL = process.env.SUPABASE_URL ?? ''
const SUPABASE_ANON_KEY = process.env.SUPABASE_ANON_KEY ?? ''
const OPENAI_API_KEY = process.env.OPENAI_API_KEY ?? ''

// üîê Initialisation Supabase uniquement si possible
const supabase = (SUPABASE_URL && SUPABASE_ANON_KEY)
  ? createClient(SUPABASE_URL, SUPABASE_ANON_KEY)
  : null

// üß† Charger les messages strat√©giques
async function getStrategicSystemMessages() {
  if (!supabase) return []

  const { data, error } = await supabase
    .from('ia_memory')
    .select('messages')
    .eq('is_strategic', true)
    .eq('role', 'system')

  if (error) {
    console.error('‚ùå Erreur Supabase:', error.message)
    return []
  }

  return data.flatMap((entry) => {
    try {
      return Array.isArray(entry.messages) ? entry.messages : JSON.parse(entry.messages)
    } catch {
      console.warn('‚ö†Ô∏è Format JSON invalide dans messages.')
      return []
    }
  })
}

// üì¨ Route POST
export async function POST(req: NextRequest) {
  const { vision, user_id = 'admin@cerdia.ai' } = await req.json()

  if (!vision || vision.trim() === '') {
    return NextResponse.json({ error: '‚ùå Aucune vision fournie.' }, { status: 400 })
  }

  const strategicMessages = await getStrategicSystemMessages()

  const baseSystem = [
    {
      role: 'system',
      content:
        "Tu es l‚ÄôIA chef strat√©gique de Investissement CERDIA. Structure et analyse des visions √† long terme, organise les √©tapes, identifie les leviers d'action, propose des modules IA.",
    },
  ]

  const messages = [
    ...(strategicMessages.length > 0 ? strategicMessages : baseSystem),
    { role: 'user', content: vision },
  ]

  // ‚ö†Ô∏è Si la cl√© OpenAI n'est pas pr√©sente, on renvoie un message neutre
  if (!OPENAI_API_KEY) {
    console.warn('‚ö†Ô∏è OPENAI_API_KEY manquante, r√©ponse mock activ√©e.')
    return NextResponse.json({ result: 'R√©ponse g√©n√©r√©e automatiquement (cl√© API manquante).' })
  }

  // ü§ñ Appel √† OpenAI
  const completion = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      Authorization: `Bearer ${OPENAI_API_KEY}`,
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: 'gpt-4',
      messages,
      temperature: 0.5,
    }),
  })

  const json = await completion.json()
  const result = json.choices?.[0]?.message?.content ?? 'R√©ponse indisponible.'

  // üìù Enregistrement m√©moire (si Supabase actif)
  if (supabase) {
    const { error: insertError } = await supabase.from('ia_memory').insert([
      {
        role: 'user',
        user_id,
        question: vision,
        answer: result,
        is_strategic: false,
      },
    ])

    if (insertError) {
      console.error('‚ö†Ô∏è Erreur enregistrement m√©moire :', insertError.message)
    }
  }

  return NextResponse.json({ result })
}
